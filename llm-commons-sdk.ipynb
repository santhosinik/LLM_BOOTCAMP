{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:22:27.143278400Z",
     "start_time": "2024-03-26T14:19:44.205726300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sap-llm-commons[all] in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (8.1.7)\n",
      "Requirement already satisfied: text-generation>=0.6.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (0.7.0)\n",
      "Requirement already satisfied: omegaconf in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (2.3.0)\n",
      "Requirement already satisfied: aleph-alpha-client in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (7.0.1)\n",
      "Requirement already satisfied: ai-core-sdk in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (2.1.1)\n",
      "Collecting langchain[openai]<=0.0.335,>=0.0.331 (from sap-llm-commons[all])\n",
      "  Obtaining dependency information for langchain[openai]<=0.0.335,>=0.0.331 from https://files.pythonhosted.org/packages/15/f9/e79403efb880425babaa91f8ab19e1b6218dc694551fa6e7f40197b5a72a/langchain-0.0.335-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.0.335-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cohere>=4.27 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (5.1.2)\n",
      "Requirement already satisfied: openai<1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from sap-llm-commons[all]) (0.28.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from click>=8.1.3->sap-llm-commons[all]) (0.4.6)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.6.4)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (4.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (3.9.3)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (0.0.92)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (8.2.3)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.3.2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (0.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from openai<1->sap-llm-commons[all]) (4.66.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.12 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from text-generation>=0.6.0->sap-llm-commons[all]) (0.22.0)\n",
      "Requirement already satisfied: ai-api-client-sdk==2.0.4 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from ai-core-sdk->sap-llm-commons[all]) (2.0.4)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from ai-api-client-sdk==2.0.4->ai-core-sdk->sap-llm-commons[all]) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from ai-api-client-sdk==2.0.4->ai-core-sdk->sap-llm-commons[all]) (3.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (2.2.1)\n",
      "Requirement already satisfied: aiodns>=3.0.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (3.1.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (2.8.3)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (0.15.2)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (9.5.0)\n",
      "Requirement already satisfied: python-liquid>=1.9.4 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (1.12.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (23.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from omegaconf->sap-llm-commons[all]) (4.9.3)\n",
      "Requirement already satisfied: pycares>=4.0.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (4.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from anyio<4.0->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from anyio<4.0->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from anyio<4.0->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from httpx>=0.21.2->cohere>=4.27->sap-llm-commons[all]) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from httpx>=0.21.2->cohere>=4.27->sap-llm-commons[all]) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere>=4.27->sap-llm-commons[all]) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation>=0.6.0->sap-llm-commons[all]) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation>=0.6.0->sap-llm-commons[all]) (2024.3.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from pydantic>=1.9.2->cohere>=4.27->sap-llm-commons[all]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from pydantic>=1.9.2->cohere>=4.27->sap-llm-commons[all]) (2.16.3)\n",
      "Requirement already satisfied: importlib-resources>=5.10.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (6.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from requests<3,>=2->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from tiktoken<0.6.0,>=0.3.2->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (2023.12.25)\n",
      "Requirement already satisfied: cffi>=1.5.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from python-dateutil>=2.8.1->python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain[openai]<=0.0.335,>=0.0.331->sap-llm-commons[all]) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (2.21)\n",
      "Using cached langchain-0.0.335-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.330\n",
      "    Uninstalling langchain-0.0.330:\n",
      "      Successfully uninstalled langchain-0.0.330\n",
      "Successfully installed langchain-0.0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sap-llm-commons[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:25:30.994345100Z",
     "start_time": "2024-03-26T14:25:24.595029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ai-api-client-sdk in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from ai-api-client-sdk) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from ai-api-client-sdk) (3.8.0)\n",
      "Requirement already satisfied: requests<3.0 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from ai-api-client-sdk) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\i322660\\pycharmprojects\\llm_bootcamp_final\\.venv\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ai-api-client-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:25:39.088086700Z",
     "start_time": "2024-03-26T14:25:37.548698800Z"
    }
   },
   "outputs": [],
   "source": [
    "# proxy configuration\n",
    "from ipywidgets import widgets\n",
    "import json\n",
    "import os\n",
    "import llm_commons.proxy.base\n",
    "\n",
    "llm_commons.proxy.base.proxy_version = 'aicore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:25:47.310671600Z",
     "start_time": "2024-03-26T14:25:41.920796400Z"
    }
   },
   "outputs": [],
   "source": [
    "from llm_commons.proxy.openai import Completion\n",
    "from llm_commons.proxy.identity import AICoreProxyClient\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from llm_commons.btp_llm.identity import BTPProxyClient\n",
    "from llm_commons.langchain.proxy import init_llm, init_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:25:49.893596300Z",
     "start_time": "2024-03-26T14:25:49.828310400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(value='8bc16ea0-ef7d-4c7b-9c1e-14da9fcb7d35', placeholder='Resource group of deployments')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25e4bd58f9ed4915ae9bf4fd983ed4bb"
      }
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_group = widgets.Text(\n",
    "    value='8bc16ea0-ef7d-4c7b-9c1e-14da9fcb7d35', # resource group\n",
    "    placeholder='Resource group of deployments',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "resource_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:25:54.342598300Z",
     "start_time": "2024-03-26T14:25:54.309043600Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('config.json') as f:\n",
    "    sk = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:26:01.086714200Z",
     "start_time": "2024-03-26T14:26:01.056388400Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['AICORE_LLM_AUTH_URL'] = sk['url']+\"/oauth/token\"\n",
    "os.environ['AICORE_LLM_CLIENT_ID'] = sk['clientid']\n",
    "os.environ['AICORE_LLM_CLIENT_SECRET'] = sk['clientsecret']\n",
    "os.environ['AICORE_LLM_API_BASE'] = sk[\"serviceurls\"][\"AI_API_URL\"]+ \"/v2\"\n",
    "os.environ['AICORE_LLM_RESOURCE_GROUP'] = resource_group.value\n",
    "os.environ['LLM_COMMONS_PROXY'] = 'aicore'\n",
    "\n",
    "llm_commons.proxy.resource_group = os.environ['AICORE_LLM_RESOURCE_GROUP']\n",
    "llm_commons.proxy.api_base = os.environ['AICORE_LLM_API_BASE']\n",
    "llm_commons.proxy.auth_url = os.environ['AICORE_LLM_AUTH_URL']\n",
    "llm_commons.proxy.client_id = os.environ['AICORE_LLM_CLIENT_ID']\n",
    "llm_commons.proxy.client_secret = os.environ['AICORE_LLM_CLIENT_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:26:06.051113800Z",
     "start_time": "2024-03-26T14:26:05.993160800Z"
    }
   },
   "outputs": [],
   "source": [
    "aic_proxy_client = AICoreProxyClient()\n",
    "btp_proxy_client = BTPProxyClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy customized fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:26:14.194523200Z",
     "start_time": "2024-03-26T14:26:14.140529Z"
    }
   },
   "outputs": [],
   "source": [
    "AICoreProxyClient.add_foundation_model_scenario(\n",
    "    scenario_id='fine-tuned-llm',\n",
    "    config_names='fine-tuned-*',\n",
    "    prediction_url_suffix='/v1/completions'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T14:26:34.912206600Z",
     "start_time": "2024-03-26T14:26:20.661639200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d67e66aa880020a1', config_id='c40b53e2-5fbb-4e04-98cc-b240cdec62f9', config_name='text-embedding-ada-002-config', deployment_id='d67e66aa880020a1', model_name='text-embedding-ada-002', created_at=datetime.datetime(2024, 3, 15, 7, 40, 15, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '2'}, custom_prediction_suffix=None),\n Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d854d892c8f61bcc', config_id='626bd56e-4b15-4a39-9fbe-11fb27fb04d4', config_name='gpt-4-32k-config', deployment_id='d854d892c8f61bcc', model_name='gpt-4-32k', created_at=datetime.datetime(2024, 3, 15, 7, 40, 15, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d0eb53a4aff0895a', config_id='7bc3ea73-218f-4a14-9c64-3ce5801d570d', config_name='gpt-4-config', deployment_id='d0eb53a4aff0895a', model_name='gpt-4', created_at=datetime.datetime(2024, 3, 15, 7, 40, 15, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/ddfa5284aeda0ad5', config_id='fbe41cac-cef8-4c05-8b9f-a01b4e297545', config_name='tiiuae--falcon-40b-instruct-config', deployment_id='ddfa5284aeda0ad5', model_name='tiiuae--falcon-40b-instruct', created_at=datetime.datetime(2024, 3, 15, 7, 40, 15, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'aicore-opensource', 'model_version': 'null'}, custom_prediction_suffix=None),\n Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/db664b0df9b83158', config_id='66d6ed48-a7be-49b6-932f-39fe7e7fe13e', config_name='gpt-35-turbo-config', deployment_id='db664b0df9b83158', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 3, 15, 7, 40, 15, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d023a20f52c649cc', config_id='2db08836-ad17-4260-be33-8aa2bc3f5838', config_name='gpt-35-turbo-16k-config', deployment_id='d023a20f52c649cc', model_name='gpt-35-turbo-16k', created_at=datetime.datetime(2024, 3, 15, 7, 40, 15, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic_proxy_client.get_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:33:05.041731800Z",
     "start_time": "2024-01-29T06:33:04.950930700Z"
    }
   },
   "outputs": [],
   "source": [
    "text_davinci_003 = Completion(deployment_id='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_davinci_003.create(model_name='our-awesome-model/v1', prompt=\"San Francisco is a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize harmonized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:33:17.687596200Z",
     "start_time": "2024-01-29T06:33:17.618454900Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = init_llm('gpt-35-turbo', proxy_client = aic_proxy_client,temperature=0., max_tokens=256, deployment_id='d4d0fce7c6bdf494', api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T15:01:42.981333Z",
     "start_time": "2024-01-18T15:01:40.857520600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"I am an AI language model developed by OpenAI, and I don't have a personal name. You can simply refer to me as OpenAI Assistant. How can I assist you today?\""
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:33:26.699774400Z",
     "start_time": "2024-01-29T06:33:26.674683500Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = init_embedding_model('text-embedding-ada-002-v2', proxy_client=aic_proxy_client, deployment_id='d026d09d4fbbad63', api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:33:51.361588Z",
     "start_time": "2024-01-29T06:33:31.107546700Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What is your name?\"\n",
    "query_embedding = embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:33:58.111261700Z",
     "start_time": "2024-01-29T06:33:57.553593500Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = [\"This is a sample document\"]\n",
    "document_embedding = embedding.embed_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Core proxy support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:34:08.163998100Z",
     "start_time": "2024-01-29T06:34:04.052554900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"As an artificial intelligence, I don't have a personal name. I'm simply known as OpenAI.\""
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_commons.proxy.base import set_proxy_version\n",
    "set_proxy_version('aicore') # for an AI Core proxy\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "chat = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "chat.predict('What is your name?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxy client - use proxies in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:34:49.146652200Z",
     "start_time": "2024-01-29T06:34:49.123748500Z"
    }
   },
   "outputs": [],
   "source": [
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from llm_commons.proxy.openai import ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:35:00.507765900Z",
     "start_time": "2024-01-29T06:34:58.870646800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"This is a test.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1706510098,\n",
      "  \"id\": \"chatcmpl-8mFWMxBM0bspGGWshDz3KYobGUIT7\",\n",
      "  \"model\": \"gpt-4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"detected\": false,\n",
      "          \"filtered\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"prompt_index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 5,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 17\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
    "\n",
    "print(ChatCompletion.create(proxy_client=aic_proxy_client, model_name='gpt-4', messages=messages, api_base=os.environ['AICORE_LLM_API_BASE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:35:06.247978600Z",
     "start_time": "2024-01-29T06:35:05.297860400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='This is a test.'\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"Say this is a test\"),\n",
    "]\n",
    "# btp_llm = ChatOpenAI(proxy_client=btp_proxy_client, deployment_id='gpt-4')\n",
    "# print(btp_llm.invoke(messages))\n",
    "aic_llm = ChatOpenAI(proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "print(aic_llm.invoke(messages))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using llm-commons with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:35:26.580722400Z",
     "start_time": "2024-01-29T06:35:26.535021400Z"
    }
   },
   "outputs": [],
   "source": [
    "# use it with langchain\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from llm_commons.langchain.proxy import OpenAI\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "template = \"Question: {question}\\nAnswer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:41:13.081992800Z",
     "start_time": "2024-01-31T04:41:12.709753300Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[43mPromptTemplate\u001B[49m(template\u001B[38;5;241m=\u001B[39mtemplate, input_variables\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      2\u001B[0m llm_chain \u001B[38;5;241m=\u001B[39m LLMChain(prompt\u001B[38;5;241m=\u001B[39mprompt, llm\u001B[38;5;241m=\u001B[39mllm, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      3\u001B[0m llm_chain\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat is the world\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms best B2B company?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'PromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain.run(\"What is the world's best B2B company?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:37:48.549378900Z",
     "start_time": "2024-01-29T06:37:44.853146300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mQuestion: What is 1+1 ?\n",
      "Answer: Let's think step by step.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'First, we have the number 1. Then, we add another 1 to it. When we combine these, we get the number 2. So, 1 + 1 = 2.'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from llm_commons.langchain.proxy import OpenAI\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "template = \"Question: {question}\\nAnswer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain.run(\"What is 1+1 ?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T06:41:40.054338100Z",
     "start_time": "2024-01-29T06:41:40.019455500Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T06:41:42.835485700Z",
     "start_time": "2024-01-29T06:41:42.812502900Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T06:41:45.445365400Z",
     "start_time": "2024-01-29T06:41:45.419816Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mQuestion: Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n",
      "Answer: Let's think step by step.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"I am quite upset that my blender lid popped off and splattered my kitchen walls with smoothie. To add to the frustration, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, my friend.\""
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T06:42:39.666700Z",
     "start_time": "2024-01-29T06:42:34.531986800Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:12:03.531216100Z",
     "start_time": "2024-01-29T07:12:03.500215400Z"
    }
   },
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:13:30.804888100Z",
     "start_time": "2024-01-29T07:13:30.761285Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:13:44.154118800Z",
     "start_time": "2024-01-29T07:13:44.108479900Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:13:58.654634200Z",
     "start_time": "2024-01-29T07:13:58.585874Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['style', 'text']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:14:38.878416100Z",
     "start_time": "2024-01-29T07:14:38.831255800Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:14:49.848962600Z",
     "start_time": "2024-01-29T07:14:49.800679800Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:15:37.858289500Z",
     "start_time": "2024-01-29T07:15:37.810850100Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:15:49.922067800Z",
     "start_time": "2024-01-29T07:15:49.812112800Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.messages.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:15:59.858121700Z",
     "start_time": "2024-01-29T07:15:59.810885700Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:16:10.902546100Z",
     "start_time": "2024-01-29T07:16:10.854745400Z"
    }
   },
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:16:38.722003300Z",
     "start_time": "2024-01-29T07:16:34.554825300Z"
    }
   },
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm quite upset that the lid to my blender came off and splattered my kitchen walls with smoothie. To add to the frustration, the warranty does not cover the cost of cleaning up my kitchen. I really need your assistance at this moment.\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:17:02.702462100Z",
     "start_time": "2024-01-29T07:17:02.658639100Z"
    }
   },
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:53:56.950452700Z",
     "start_time": "2024-01-29T07:53:56.745147700Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:54:54.854733Z",
     "start_time": "2024-01-29T07:54:54.803856300Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T07:59:42.372825Z",
     "start_time": "2024-01-29T07:59:42.317547800Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Santhosini\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Hello, Santhosini! It's a pleasure to meet you. How can I assist you today?\""
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Santhosini\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:16.143499600Z",
     "start_time": "2024-01-29T08:00:11.692017900Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Santhosini\n",
      "AI: Hello, Santhosini! It's a pleasure to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'The sum of 1+1 is 2.'"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:34.256409900Z",
     "start_time": "2024-01-29T08:00:32.754179900Z"
    }
   },
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Santhosini\n",
      "AI: Hello, Santhosini! It's a pleasure to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The sum of 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Your name is Santhosini.'"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:51.724958Z",
     "start_time": "2024-01-29T08:00:50.170189800Z"
    }
   },
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Santhosini\n",
      "AI: Hello, Santhosini! It's a pleasure to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The sum of 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Santhosini.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T08:01:03.302790900Z",
     "start_time": "2024-01-29T08:01:03.228194800Z"
    }
   },
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de4a507b2430954be05ae5f9be35829c657a2682621712b642b28df909ac005f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
